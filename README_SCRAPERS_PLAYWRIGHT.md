# ğŸ­ SCRAPERS COM PLAYWRIGHT - APOSTAPRO

Sistema avanÃ§ado de web scraping usando **Playwright da Microsoft** para coleta de dados esportivos de mÃºltiplas fontes.

## ğŸš€ **VANTAGENS DO PLAYWRIGHT**

### âœ… **Performance Superior**
- **Auto-wait inteligente** para elementos
- **Suporte nativo** para mÃºltiplos navegadores (Chromium, Firefox, WebKit)
- **Modo headless otimizado** para produÃ§Ã£o
- **InterceptaÃ§Ã£o de requisiÃ§Ãµes** para melhor controle

### âœ… **Anti-DetecÃ§Ã£o AvanÃ§ado**
- **User agents rotativos** para simular navegadores reais
- **Headers personalizados** para evitar bloqueios
- **Comportamento humano** simulado
- **Rate limiting inteligente** para respeitar limites dos sites

### âœ… **Funcionalidades AvanÃ§adas**
- **Screenshots automÃ¡ticos** para debug
- **GravaÃ§Ã£o de vÃ­deo** das sessÃµes
- **Arquivos HAR** para anÃ¡lise de rede
- **Retry automÃ¡tico** em falhas
- **Logging detalhado** para monitoramento

## ğŸ—ï¸ **ARQUITETURA DO SISTEMA**

```
ğŸ“ Coleta_de_dados/
â”œâ”€â”€ ğŸ“ apis/
â”‚   â”œâ”€â”€ ğŸ­ playwright_base.py          # Classe base para todos os scrapers
â”‚   â”œâ”€â”€ ğŸ† fbref/
â”‚   â”‚   â””â”€â”€ playwright_scraper.py      # Scraper do FBRef
â”‚   â”œâ”€â”€ âš½ sofascore/
â”‚   â”‚   â””â”€â”€ playwright_scraper.py      # Scraper do SofaScore
â”‚   â””â”€â”€ âš™ï¸ scraper_config.py           # ConfiguraÃ§Ã£o centralizada
â”œâ”€â”€ ğŸ¯ orquestrador_scrapers.py        # Orquestrador principal
â””â”€â”€ ğŸ“Š demo_playwright_scrapers.py     # Script de demonstraÃ§Ã£o
```

## ğŸ¯ **SCRAPERS IMPLEMENTADOS**

### ğŸ† **FBRef Scraper**
- **URLs**: 10+ competiÃ§Ãµes principais (Premier League, La Liga, Champions League, etc.)
- **Dados**: EstatÃ­sticas de clubes, partidas, jogadores
- **Rate Limit**: 2 segundos entre requisiÃ§Ãµes
- **Funcionalidades**: PaginaÃ§Ã£o automÃ¡tica, extraÃ§Ã£o de tabelas

### âš½ **SofaScore Scraper**
- **URLs**: Times principais, torneios, partidas ao vivo
- **Dados**: Resultados em tempo real, estatÃ­sticas, odds
- **Rate Limit**: 3 segundos entre requisiÃ§Ãµes (mais conservador)
- **Funcionalidades**: Coleta de partidas ao vivo, histÃ³rico de times

### ğŸ“Š **FlashScore Scraper** (Configurado)
- **URLs**: 5 ligas principais
- **Dados**: Resultados, estatÃ­sticas, odds
- **Rate Limit**: 2.5 segundos entre requisiÃ§Ãµes

### ğŸ“ˆ **WhoScored Scraper** (Configurado)
- **URLs**: 5 regiÃµes principais
- **Dados**: EstatÃ­sticas avanÃ§adas, anÃ¡lises tÃ¡ticas
- **Rate Limit**: 3 segundos entre requisiÃ§Ãµes

## âš™ï¸ **CONFIGURAÃ‡ÃƒO**

### ğŸ”§ **ConfiguraÃ§Ã£o Base**
```python
from Coleta_de_dados.apis.scraper_config import ScraperConfig

# ConfiguraÃ§Ã£o para desenvolvimento
config = ScraperConfig.get_playwright_config(
    headless=False,      # Mostrar navegador para debug
    timeout=30000,       # 30 segundos
    enable_video=True    # Gravar vÃ­deo para debug
)

# ConfiguraÃ§Ã£o para produÃ§Ã£o
config = ScraperConfig.get_playwright_config(
    headless=True,       # Executar em background
    timeout=120000,      # 2 minutos para estabilidade
    enable_video=False   # NÃ£o gravar vÃ­deo em produÃ§Ã£o
)
```

### ğŸŒ **ConfiguraÃ§Ãµes por Ambiente**
```python
# Desenvolvimento
config = get_config_for_environment("dev")

# ProduÃ§Ã£o
config = get_config_for_environment("prod")
```

### ğŸ“Š **Rate Limiting ConfigurÃ¡vel**
```python
RATE_LIMITING = {
    "global_delay": 1.0,           # Delay mÃ­nimo entre requisiÃ§Ãµes
    "max_requests_per_minute": 30, # MÃ¡ximo por minuto
    "max_requests_per_hour": 1000, # MÃ¡ximo por hora
    "backoff_factor": 2.0,         # Fator de backoff exponencial
    "max_retries": 5               # MÃ¡ximo de tentativas
}
```

## ğŸš€ **USO BÃSICO**

### ğŸ“ **Exemplo Simples**
```python
from Coleta_de_dados.apis.fbref.playwright_scraper import FBRefPlaywrightScraper

async def coletar_dados():
    async with FBRefPlaywrightScraper(headless=False) as scraper:
        # Coletar competiÃ§Ãµes
        competitions = await scraper.collect_competitions()
        print(f"âœ… {len(competitions)} competiÃ§Ãµes encontradas")
        
        # Coletar partidas
        matches = await scraper.collect_matches(competitions[0]['url'])
        print(f"âœ… {len(matches)} partidas coletadas")
        
        # Screenshot para debug
        await scraper.take_screenshot("fbref_demo.png")

# Executar
import asyncio
asyncio.run(coletar_dados())
```

### ğŸ­ **Exemplo com Funcionalidades AvanÃ§adas**
```python
from Coleta_de_dados.apis.playwright_base import PlaywrightBaseScraper

async def exemplo_avancado():
    async with PlaywrightBaseScraper(
        headless=False,
        enable_video=True,
        enable_har=True
    ) as scraper:
        
        # Navegar para pÃ¡gina
        await scraper.navigate_to("https://example.com")
        
        # Aguardar elemento especÃ­fico
        await scraper.wait_for_element("h1")
        
        # Executar JavaScript
        title = await scraper.evaluate_javascript("document.title")
        print(f"TÃ­tulo: {title}")
        
        # Screenshot
        await scraper.take_screenshot("exemplo.png")
        
        # Dados interceptados
        intercepted = scraper.get_intercepted_data()
        print(f"RequisiÃ§Ãµes: {len(intercepted['requests'])}")
```

## ğŸ¯ **ORQUESTADOR CENTRALIZADO**

### ğŸ”„ **ExecuÃ§Ã£o Coordenada**
```python
from Coleta_de_dados.orquestrador_scrapers import OrquestradorScrapers

async def executar_coleta():
    orchestrator = OrquestradorScrapers(environment="dev")
    
    # Iniciar
    await orchestrator.start()
    
    # Executar ciclo Ãºnico
    stats = await orchestrator.run_collection_cycle("teste")
    print(f"Dados coletados: {stats['total_data_collected']}")
    
    # Parar
    await orchestrator.stop()

# Executar
asyncio.run(executar_coleta())
```

### â° **Agendamento AutomÃ¡tico**
```python
# Executar coleta a cada hora
await orchestrator.run_scheduled_collection(interval_minutes=60)
```

### ğŸ“Š **Monitoramento de SaÃºde**
```python
# Verificar status
health = orchestrator.get_health_status()
print(f"Status: {health['overall_status']}")
print(f"Taxa de sucesso: {health['success_rate']:.2%}")
```

## ğŸ§ª **TESTES E DEMONSTRAÃ‡ÃƒO**

### ğŸ¬ **Script de DemonstraÃ§Ã£o**
```bash
# Executar demonstraÃ§Ã£o completa
python demo_playwright_scrapers.py
```

### ğŸ“‹ **Testes DisponÃ­veis**
1. **Funcionalidades Base do Playwright**
   - NavegaÃ§Ã£o, screenshots, interceptaÃ§Ã£o
2. **Scraper do FBRef**
   - Coleta de competiÃ§Ãµes e partidas
3. **Scraper do SofaScore**
   - Partidas ao vivo e histÃ³rico de times

## ğŸ“ **ESTRUTURA DE ARQUIVOS GERADOS**

### ğŸ“¸ **Screenshots**
```
screenshots/
â”œâ”€â”€ fbref/
â”‚   â”œâ”€â”€ fbref_demo.png
â”‚   â””â”€â”€ error_competitions.png
â”œâ”€â”€ sofascore/
â”‚   â”œâ”€â”€ sofascore_demo.png
â”‚   â””â”€â”€ error_live_matches.png
â””â”€â”€ playwright_features_demo.png
```

### ğŸ“Š **Dados Coletados**
```
collected_data/
â”œâ”€â”€ fbref_data_20250814_153000.json
â”œâ”€â”€ sofascore_data_20250814_153000.json
â””â”€â”€ ...
```

### ğŸ“ˆ **EstatÃ­sticas**
```
stats/
â”œâ”€â”€ cycle_test_cycle_20250814_153000.json
â”œâ”€â”€ orchestrator_final_20250814_153000.json
â””â”€â”€ ...
```

### ğŸ¥ **VÃ­deos (se habilitado)**
```
screenshots/
â”œâ”€â”€ session_20250814_153000.mp4
â””â”€â”€ ...
```

### ğŸ“‹ **Arquivos HAR**
```
screenshots/
â”œâ”€â”€ session_20250814_153000.har
â””â”€â”€ ...
```

## ğŸ”§ **INSTALAÃ‡ÃƒO E CONFIGURAÃ‡ÃƒO**

### ğŸ“¦ **DependÃªncias**
```bash
# Instalar Playwright
pip install playwright

# Instalar navegadores
playwright install
```

### ğŸ **VerificaÃ§Ã£o da InstalaÃ§Ã£o**
```python
# Testar se Playwright estÃ¡ funcionando
from playwright.async_api import async_playwright

async def test_playwright():
    async with async_playwright() as p:
        browser = await p.chromium.launch()
        page = await browser.new_page()
        await page.goto("https://example.com")
        print("âœ… Playwright funcionando!")
        await browser.close()

asyncio.run(test_playwright())
```

## ğŸš¨ **TRATAMENTO DE ERROS**

### âš ï¸ **Erros Comuns**
- **Timeout**: Aumentar `timeout` na configuraÃ§Ã£o
- **Elemento nÃ£o encontrado**: Verificar seletores CSS
- **Rate limiting**: Aumentar `rate_limit_delay`
- **Navegador nÃ£o inicia**: Verificar instalaÃ§Ã£o do Playwright

### ğŸ”„ **Retry AutomÃ¡tico**
```python
# ConfiguraÃ§Ã£o de retry
max_retries = 3
retry_delay = 2

# O sistema tenta automaticamente em caso de falha
```

## ğŸ“Š **MONITORAMENTO E LOGS**

### ğŸ“ **Logs AutomÃ¡ticos**
```
logs/
â””â”€â”€ scrapers.log
```

### ğŸ“Š **MÃ©tricas Coletadas**
- Taxa de sucesso por scraper
- Tempo de execuÃ§Ã£o por ciclo
- Quantidade de dados coletados
- Erros e falhas
- Uptime do sistema

## ğŸš€ **PRÃ“XIMOS PASSOS**

### ğŸ”® **Funcionalidades Futuras**
1. **Mais Scrapers**
   - ESPN, Transfermarkt, etc.
2. **Sistema de Proxies**
   - RotaÃ§Ã£o automÃ¡tica de IPs
3. **Cache Inteligente**
   - Evitar re-coleta de dados
4. **NotificaÃ§Ãµes**
   - Email, Slack, Discord
5. **Dashboard Web**
   - Monitoramento em tempo real

### ğŸ”§ **OtimizaÃ§Ãµes**
1. **ParalelizaÃ§Ã£o**
   - MÃºltiplos scrapers simultÃ¢neos
2. **DistribuiÃ§Ã£o**
   - Scrapers em diferentes servidores
3. **Machine Learning**
   - DetecÃ§Ã£o automÃ¡tica de mudanÃ§as nos sites

## ğŸ“š **REFERÃŠNCIAS**

### ğŸ”— **DocumentaÃ§Ã£o Oficial**
- [Playwright Python](https://playwright.dev/python/)
- [Playwright API Reference](https://playwright.dev/python/docs/api/class-playwright)

### ğŸ“– **Tutoriais e Exemplos**
- [Web Scraping com Playwright](https://playwright.dev/python/docs/web-scraping)
- [Anti-Detection Techniques](https://playwright.dev/python/docs/network)

## ğŸ¤ **CONTRIBUIÃ‡ÃƒO**

### ğŸ“ **Como Contribuir**
1. Fork do repositÃ³rio
2. Criar branch para feature
3. Implementar funcionalidade
4. Adicionar testes
5. Fazer pull request

### ğŸ› **Reportar Bugs**
- Usar issues do GitHub
- Incluir logs de erro
- Descrever passos para reproduzir

## ğŸ“„ **LICENÃ‡A**

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo LICENSE para detalhes.

---

## ğŸ‰ **CONCLUSÃƒO**

O sistema de scrapers com Playwright oferece uma soluÃ§Ã£o robusta, escalÃ¡vel e profissional para coleta de dados esportivos. Com funcionalidades avanÃ§adas de anti-detecÃ§Ã£o, monitoramento automÃ¡tico e arquitetura modular, estÃ¡ pronto para uso em produÃ§Ã£o.

**ğŸš€ Playwright Ã© o futuro do web scraping! ğŸ­**
