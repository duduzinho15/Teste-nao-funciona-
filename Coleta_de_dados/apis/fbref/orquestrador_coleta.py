import logging
import time
import sys
import os
import multiprocessing
import queue
from typing import Dict, Any, Optional, Callable
from dataclasses import dataclass
from contextlib import contextmanager
import traceback
import json
from datetime import datetime
# Configura√ß√£o de paths
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../"))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)
# Importa√ß√µes dos m√≥dulos otimizados
from Banco_de_dados.criar_banco import criar_todas_as_tabelas
from Coleta_de_dados.apis.fbref.fbref_integrado import main as descobrir_links
from Coleta_de_dados.apis.fbref.coletar_dados_partidas import main as coletar_partidas
from Coleta_de_dados.apis.fbref.coletar_estatisticas_detalhadas import main as coletar_estatisticas
from Coleta_de_dados.apis.fbref.fbref_criar_tabela_rotulada import main as processar_dados
from Coleta_de_dados.apis.fbref.gerar_relatorio_final import main as gerar_relatorio
logger = logging.getLogger(__name__)

# Worker function for multiprocessing - must be at module level for Windows compatibility
def _timeout_worker(func_and_args_queue, result_queue):
    """Worker function for timeout execution - defined at module level for Windows pickling."""
    try:
        func, args, kwargs = func_and_args_queue.get()
        if args and kwargs:
            result = func(*args, **kwargs)
        elif args:
            result = func(*args)
        elif kwargs:
            result = func(**kwargs)
        else:
            result = func()
        result_queue.put(result)
    except Exception as e:
        result_queue.put(e)
@dataclass
class EtapaExecucao:
    """Classe para definir uma etapa da pipeline."""
    nome: str
    descricao: str
    funcao: Callable
    obrigatoria: bool = True
    timeout: Optional[int] = None
@dataclass
class ResultadoEtapa:
    """Classe para armazenar o resultado de uma etapa."""
    nome: str
    sucesso: bool
    tempo_execucao: float
    erro: Optional[str] = None
    dados_retorno: Optional[Any] = None
@dataclass
class EstatisticasPipeline:
    """Classe para estat√≠sticas gerais da pipeline."""
    tempo_total: float = 0.0
    etapas_executadas: int = 0
    etapas_com_sucesso: int = 0
    etapas_com_erro: int = 0
    dados_coletados: Dict[str, int] = None
    def __post_init__(self):
        if self.dados_coletados is None:
            self.dados_coletados = {}
class OrquestradorColeta:
    """Classe principal para orquestra√ß√£o da pipeline de coleta."""
    
    def __init__(self, config_arquivo: Optional[str] = None):
        self.config = self._carregar_configuracao(config_arquivo)
        self.resultados_etapas = []
        self.stats = EstatisticasPipeline()
        # Defini√ß√£o das etapas da pipeline
        self.etapas = [
            EtapaExecucao(
                nome="preparacao_banco",
                descricao="Prepara√ß√£o do Banco de Dados",
                funcao=self._executar_preparacao_banco,
                timeout=300  # 5 minutos
            ),
            EtapaExecucao(
                nome="descoberta_links",
                descricao="Descoberta de Competi√ß√µes e Temporadas",
                funcao=self._executar_descoberta_links,
                timeout=900  # 15 minutos (reduzido de 30 minutos)
            ),
            EtapaExecucao(
                nome="verificacao_extracao",
                descricao="Verifica√ß√£o da Completude da Extra√ß√£o",
                funcao=self._executar_verificacao_extracao,
                timeout=900  # 15 minutos
            ),
            EtapaExecucao(
                nome="coleta_partidas",
                descricao="Coleta de Dados de Partidas",
                funcao=self._executar_coleta_partidas,
                timeout=3600  # 1 hora
            ),
            EtapaExecucao(
                nome="coleta_estatisticas",
                descricao="Coleta de Estat√≠sticas Detalhadas",
                funcao=self._executar_coleta_estatisticas,
                timeout=7200  # 2 horas
            ),
            EtapaExecucao(
                nome="coleta_clubes",
                descricao="Coleta de Dados de Clubes",
                funcao=self._executar_coleta_clubes,
                timeout=3600  # 1 hora
            ),
            EtapaExecucao(
                nome="coleta_jogadores",
                descricao="Coleta de Dados de Jogadores",
                funcao=self._executar_coleta_jogadores,
                timeout=3600  # 1 hora
            ),
            EtapaExecucao(
                nome="processamento_dados",
                descricao="Processamento e Rotula√ß√£o dos Dados para IA",
                funcao=self._executar_processamento_dados,
                timeout=600  # 10 minutos
            ),
            EtapaExecucao(
                nome="geracao_relatorio",
                descricao="Gera√ß√£o do Relat√≥rio Final de Coleta",
                funcao=self._executar_geracao_relatorio,
                obrigatoria=False,  # N√£o cr√≠tica
                timeout=300  # 5 minutos
            )
        ]
    def _carregar_configuracao(self, config_arquivo: Optional[str]) -> Dict[str, Any]:
        """Carrega configura√ß√µes da pipeline."""
        config_padrao = {
            'continuar_em_erro': True,  # ‚úÖ Continuar mesmo com erros n√£o cr√≠ticos
            'salvar_logs_detalhados': True,
            'backup_antes_execucao': True,
            'timeout_global': 14400,  # 4 horas
            'intervalo_checkpoint': 300,  # 5 minutos
            'modo_teste': False,  # ‚úÖ Modo teste desabilitado por padr√£o
            'limite_competicoes': None,  # ‚úÖ Sem limite por padr√£o
        }
        if config_arquivo and os.path.exists(config_arquivo):
            try:
                with open(config_arquivo, 'r', encoding='utf-8') as f:
                    config_carregada = json.load(f)
                config_padrao.update(config_carregada)
            except Exception as e:
                logger.warning(f"Erro ao carregar configura√ß√£o: {e}. Usando configura√ß√£o padr√£o.")
        return config_padrao
    @contextmanager
    def _timeout_context(self, seconds: Optional[int]):
        """Context manager para timeout de execu√ß√£o que funciona no Windows."""
        if seconds is None:
            yield
            return
            
        import threading
        import signal
        
        # Verifica se estamos no Windows
        if os.name == 'nt':  # Windows
            # Implementa√ß√£o para Windows usando threading
            result = {'value': None, 'exception': None}
            
            def target():
                try:
                    result['value'] = yield
                except Exception as e:
                    result['exception'] = e
            
            def timeout_handler():
                result['exception'] = TimeoutError(f"Opera√ß√£o excedeu timeout de {seconds} segundos")
            
            timer = threading.Timer(seconds, timeout_handler)
            timer.start()
            
            try:
                yield
                timer.cancel()
                
                if result['exception']:
                    raise result['exception']
                    
            except Exception as e:
                timer.cancel()
                raise e
                
        else:
            # Implementa√ß√£o para Unix/Linux usando signal
            def timeout_handler(signum, frame):
                raise TimeoutError(f"Opera√ß√£o excedeu timeout de {seconds} segundos")
            
            if hasattr(signal, 'SIGALRM'):
                old_handler = signal.signal(signal.SIGALRM, timeout_handler)
                signal.alarm(seconds)
                try:
                    yield
                finally:
                    signal.alarm(0)
                    signal.signal(signal.SIGALRM, old_handler)
            else:
                logger.warning("Timeout n√£o suportado neste sistema. Executando sem timeout.")
                yield
    def _run_with_timeout(self, func, timeout, *args, **kwargs):
        """Executa fun√ß√£o com timeout universal"""
        # Use queues for communication with the worker process
        func_queue = multiprocessing.Queue()
        result_queue = multiprocessing.Queue()
        
        # Put function and arguments in the queue
        func_queue.put((func, args, kwargs))
        
        # Start worker process
        p = multiprocessing.Process(target=_timeout_worker, args=(func_queue, result_queue))
        p.start()
        p.join(timeout)
        
        if p.is_alive():
            p.terminate()
            p.join()
            raise TimeoutError(f"Timeout ap√≥s {timeout}s")
        
        # Get result from queue
        if not result_queue.empty():
            result = result_queue.get()
            if isinstance(result, Exception):
                raise result
            return result
        else:
            raise RuntimeError("Processo terminou sem retornar resultado")
    def _executar_etapa_com_tratamento(self, etapa: EtapaExecucao) -> ResultadoEtapa:
        """Executa uma etapa individual com tratamento completo de erros."""
        logger.info(f"\n--- [ETAPA {self.stats.etapas_executadas + 1} de {len(self.etapas)}] Executando: {etapa.descricao} ---")
        start_time = time.time()
        resultado = ResultadoEtapa(nome=etapa.nome, sucesso=False, tempo_execucao=0.0)
        try:
            with self._timeout_context(etapa.timeout):
                # Alterado para usar _run_with_timeout
                dados_retorno = self._run_with_timeout(etapa.funcao, etapa.timeout)
                resultado.sucesso = True
                resultado.dados_retorno = dados_retorno
            logger.info(f"--- [ETAPA {self.stats.etapas_executadas + 1}] Finalizada com sucesso! ---")
        except TimeoutError as e:
            resultado.erro = f"Timeout: {str(e)}"
            logger.error(f"--- [ETAPA {self.stats.etapas_executadas + 1}] TIMEOUT: {e} ---")
        except Exception as e:
            resultado.erro = str(e)
            logger.error(f"--- [ETAPA {self.stats.etapas_executadas + 1}] ERRO: {e} ---")
            if logger.isEnabledFor(logging.DEBUG):
                logger.debug(traceback.format_exc())
        finally:
            resultado.tempo_execucao = time.time() - start_time
            self.stats.etapas_executadas += 1
            if resultado.sucesso:
                self.stats.etapas_com_sucesso += 1
            else:
                self.stats.etapas_com_erro += 1
        return resultado
    def _deve_continuar_execucao(self, resultado: ResultadoEtapa, etapa: EtapaExecucao) -> bool:
        """Determina se a pipeline deve continuar ap√≥s uma etapa."""
        if resultado.sucesso:
            logger.info(f"‚úÖ Etapa '{etapa.nome}' executada com sucesso - continuando pipeline")
            return True
        
        if not etapa.obrigatoria:
            logger.warning(f"‚ö†Ô∏è Etapa n√£o obrigat√≥ria '{etapa.nome}' falhou - continuando pipeline")
            logger.info(f"üìã Detalhes do erro: {resultado.erro}")
            return True
        
        if self.config.get('continuar_em_erro', False):
            logger.warning(f"üîÑ Etapa obrigat√≥ria '{etapa.nome}' falhou - continuando por configura√ß√£o")
            logger.warning(f"üìã Detalhes do erro: {resultado.erro}")
            return True
        
        logger.error(f"üõë Etapa obrigat√≥ria '{etapa.nome}' falhou - interrompendo pipeline")
        logger.error(f"üìã Detalhes do erro: {resultado.erro}")
        return False
    def _salvar_checkpoint(self) -> None:
        """Salva um checkpoint do estado atual da pipeline."""
        try:
            checkpoint_data = {
                'timestamp': datetime.now().isoformat(),
                'etapas_executadas': self.stats.etapas_executadas,
                'etapas_com_sucesso': self.stats.etapas_com_sucesso,
                'resultados': [
                    {
                        'nome': r.nome,
                        'sucesso': r.sucesso,
                        'tempo_execucao': r.tempo_execucao,
                        'erro': r.erro
                    }
                    for r in self.resultados_etapas
                ]
            }
            checkpoint_file = os.path.join(PROJECT_ROOT, 'checkpoint_pipeline.json')
            with open(checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)
            logger.debug(f"Checkpoint salvo em: {checkpoint_file}")
        except Exception as e:
            logger.warning(f"Erro ao salvar checkpoint: {e}")
    def _gerar_relatorio_execucao(self) -> None:
        """Gera relat√≥rio detalhado da execu√ß√£o da pipeline."""
        logger.info("\n" + "="*80)
        logger.info("üìä RELAT√ìRIO FINAL DA PIPELINE")
        logger.info("="*80)
        logger.info(f"‚è±Ô∏è  Tempo total de execu√ß√£o: {time.strftime('%H:%M:%S', time.gmtime(self.stats.tempo_total))}")
        logger.info(f"üìà Etapas executadas: {self.stats.etapas_executadas}/{len(self.etapas)}")
        logger.info(f"‚úÖ Etapas com sucesso: {self.stats.etapas_com_sucesso}")
        logger.info(f"‚ùå Etapas com erro: {self.stats.etapas_com_erro}")
        logger.info("\nüìã DETALHES POR ETAPA:")
        for resultado in self.resultados_etapas:
            status = "‚úÖ SUCESSO" if resultado.sucesso else "‚ùå ERRO"
            tempo_str = time.strftime('%H:%M:%S', time.gmtime(resultado.tempo_execucao))
            logger.info(f"  {status} | {resultado.nome:<20} | {tempo_str}")
            if resultado.erro:
                logger.info(f"    ‚îî‚îÄ Erro: {resultado.erro}")
        # Estat√≠sticas de dados coletados
        if self.stats.dados_coletados:
            logger.info("\nüìä DADOS COLETADOS:")
            for chave, valor in self.stats.dados_coletados.items():
                logger.info(f"  {chave}: {valor:,}")
        logger.info("="*80)
    # M√©todos wrapper para as etapas individuais
    def _executar_preparacao_banco(self):
        """Wrapper para prepara√ß√£o do banco de dados."""
        logger.info("Iniciando prepara√ß√£o do banco de dados...")
        return criar_todas_as_tabelas()
    def _executar_descoberta_links(self):
        """Wrapper para descoberta de links com controle de modo teste."""
        modo_teste = self.config.get('modo_teste', False)
        logger.info(f"Iniciando descoberta de competi√ß√µes e temporadas (modo_teste={modo_teste})")
        if modo_teste:
            logger.info("üß™ MODO TESTE ATIVADO - Processamento limitado")
        from .fbref_integrado import main
        return main(modo_teste=modo_teste)
    def _executar_coleta_partidas(self):
        """Wrapper para coleta de partidas."""
        logger.info("Iniciando coleta de dados de partidas...")
        resultado = coletar_partidas()
        if isinstance(resultado, dict):
            self.stats.dados_coletados.update({
                'partidas_coletadas': resultado.get('partidas_encontradas', 0),
                'links_processados': resultado.get('links_processados', 0)
            })
        return resultado
    def _executar_coleta_estatisticas(self):
        """Wrapper para coleta de estat√≠sticas."""
        logger.info("Iniciando coleta de estat√≠sticas detalhadas...")
        resultado = coletar_estatisticas()
        if isinstance(resultado, dict):
            self.stats.dados_coletados.update({
                'jogadores_processados': resultado.get('jogadores_processados', 0),
                'partidas_com_stats': resultado.get('partidas_processadas', 0)
            })
        return resultado
    def _executar_processamento_dados(self):
        """Wrapper para processamento de dados."""
        logger.info("Iniciando processamento e rotula√ß√£o dos dados...")
        return processar_dados()
    def _executar_verificacao_extracao(self):
        """Wrapper para verifica√ß√£o da completude da extra√ß√£o."""
        logger.info("Iniciando verifica√ß√£o da completude da extra√ß√£o...")
        from .verificar_extracao import VerificadorExtracao
        verificador = VerificadorExtracao()
        return verificador.executar_verificacao_completa()

    def _executar_coleta_clubes(self):
        """Wrapper para coleta de clubes."""
        logger.info("Iniciando coleta de dados de clubes...")
        from .coletar_clubes import ColetorClubes
        coletor = ColetorClubes()
        resultado = coletor.executar_coleta_completa()
        if isinstance(resultado, dict):
            self.stats.dados_coletados.update({
                'paises_processados': resultado.get('paises_processados', 0),
                'clubes_encontrados': resultado.get('clubes_encontrados', 0),
                'clubes_masculino': resultado.get('clubes_masculino', 0),
                'clubes_feminino': resultado.get('clubes_feminino', 0)
            })
        return resultado

    def _executar_coleta_jogadores(self):
        """Wrapper para coleta de jogadores."""
        logger.info("Iniciando coleta de dados de jogadores...")
        from .coletar_jogadores import ColetorJogadores
        coletor = ColetorJogadores()
        resultado = coletor.executar_coleta_completa()
        if isinstance(resultado, dict):
            self.stats.dados_coletados.update({
                'paises_jogadores_processados': resultado.get('paises_processados', 0),
                'jogadores_encontrados': resultado.get('jogadores_encontrados', 0),
                'jogadores_com_stats': resultado.get('jogadores_com_stats', 0)
            })
        return resultado

    def _executar_geracao_relatorio(self):
        """Wrapper para gera√ß√£o de relat√≥rio."""
        logger.info("Iniciando gera√ß√£o do relat√≥rio final...")
        return gerar_relatorio()
    def executar_pipeline_completa(self) -> bool:
        """
        Executa todos os scripts da pipeline de dados em sequ√™ncia.
        Returns:
            bool: True se a pipeline foi executada com sucesso
        """
        start_time = time.time()
        pipeline_sucesso = True
        logger.info("üöÄüöÄüöÄ INICIANDO A PIPELINE COMPLETA DE DADOS DO FBREF üöÄüöÄüöÄ")
        logger.info(f"Configura√ß√£o: {self.config}")
        try:
            # Executa cada etapa
            for etapa in self.etapas:
                # Checkpoint peri√≥dico
                if time.time() - start_time > self.config.get('intervalo_checkpoint', 300):
                    self._salvar_checkpoint()
                # Executa a etapa
                resultado = self._executar_etapa_com_tratamento(etapa)
                self.resultados_etapas.append(resultado)
                # Verifica se deve continuar
                if not self._deve_continuar_execucao(resultado, etapa):
                    pipeline_sucesso = False
                    break
            # Checkpoint final
            self._salvar_checkpoint()
        except KeyboardInterrupt:
            logger.warning("üõë Pipeline interrompida pelo usu√°rio (Ctrl+C)")
            pipeline_sucesso = False
        except Exception as e:
            logger.critical(f"üö®üö®üö® ERRO CR√çTICO NA PIPELINE! üö®üö®üö®", exc_info=True)
            pipeline_sucesso = False
        finally:
            # Calcular estat√≠sticas finais
            self.stats.tempo_total = time.time() - start_time
            # Gerar relat√≥rio final
            self._gerar_relatorio_execucao()
            # Status final
            if pipeline_sucesso and self.stats.etapas_com_erro == 0:
                logger.info("‚úÖ‚úÖ‚úÖ PIPELINE COMPLETA FINALIZADA COM SUCESSO! ‚úÖ‚úÖ‚úÖ")
            elif pipeline_sucesso:
                logger.warning("‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è PIPELINE FINALIZADA COM AVISOS ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è")
            else:
                logger.error("‚ùå‚ùå‚ùå PIPELINE FINALIZADA COM ERROS ‚ùå‚ùå‚ùå")
        return pipeline_sucesso
    def executar_etapa_individual(self, nome_etapa: str) -> bool:
        """
        Executa uma etapa individual da pipeline.
        Args:
            nome_etapa: Nome da etapa a ser executada
        Returns:
            bool: True se a etapa foi executada com sucesso
        """
        etapa = next((e for e in self.etapas if e.nome == nome_etapa), None)
        if not etapa:
            logger.error(f"Etapa '{nome_etapa}' n√£o encontrada.")
            return False
        logger.info(f"üöÄ Executando etapa individual: {etapa.descricao}")
        resultado = self._executar_etapa_com_tratamento(etapa)
        self.resultados_etapas.append(resultado)
        return resultado.sucesso
    def listar_etapas(self) -> None:
        """Lista todas as etapas dispon√≠veis."""
        logger.info("üìã ETAPAS DISPON√çVEIS NA PIPELINE:")
        for i, etapa in enumerate(self.etapas, 1):
            obrigatoria = "OBRIGAT√ìRIA" if etapa.obrigatoria else "OPCIONAL"
            timeout_info = f"(timeout: {etapa.timeout}s)" if etapa.timeout else ""
            logger.info(f"  {i}. {etapa.nome} - {etapa.descricao} [{obrigatoria}] {timeout_info}")
def executar_pipeline_completa(config_arquivo: Optional[str] = None) -> bool:
    """
    Fun√ß√£o utilit√°ria para executar a pipeline completa.
    Args:
        config_arquivo: Caminho para arquivo de configura√ß√£o opcional
    Returns:
        bool: True se executou com sucesso
    """
    orquestrador = OrquestradorColeta(config_arquivo)
    return orquestrador.executar_pipeline_completa()
def main():
    """Fun√ß√£o principal para execu√ß√£o standalone."""
    import argparse
    parser = argparse.ArgumentParser(description='Orquestrador da Pipeline FBRef')
    parser.add_argument('--config', help='Arquivo de configura√ß√£o JSON')
    parser.add_argument('--etapa', help='Executar apenas uma etapa espec√≠fica')
    parser.add_argument('--listar', action='store_true', help='Listar etapas dispon√≠veis')
    parser.add_argument('--debug', action='store_true', help='Ativar logging debug')
    args = parser.parse_args()
    # Configurar logging
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    # Criar orquestrador
    orquestrador = OrquestradorColeta(args.config)
    # Executar a√ß√£o solicitada
    if args.listar:
        orquestrador.listar_etapas()
        return True
    elif args.etapa:
        return orquestrador.executar_etapa_individual(args.etapa)
    else:
        return orquestrador.executar_pipeline_completa()
if __name__ == "__main__":
    sucesso = main()
    sys.exit(0 if sucesso else 1)