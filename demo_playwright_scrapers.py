"""
DEMONSTRA√á√ÉO DOS SCRAPERS COM PLAYWRIGHT
========================================

Script para demonstrar e testar os scrapers usando Playwright da Microsoft.
Mostra as funcionalidades avan√ßadas como anti-detec√ß√£o, screenshots autom√°ticos,
e intercepta√ß√£o de requisi√ß√µes.

Autor: Sistema de Coleta de Dados
Data: 2025-08-14
Vers√£o: 1.0
"""

import asyncio
import logging
import time
from pathlib import Path
from datetime import datetime

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def demo_fbref_scraper():
    """Demonstra o scraper do FBRef com Playwright."""
    print("\n" + "="*60)
    print("üé≠ DEMONSTRA√á√ÉO DO SCRAPER FBREF COM PLAYWRIGHT")
    print("="*60)
    
    try:
        from Coleta_de_dados.apis.fbref.playwright_scraper import FBRefPlaywrightScraper
        
        # URLs de teste
        competition_urls = [
            "https://fbref.com/en/comps/9/Premier-League-Stats",
            "https://fbref.com/en/comps/12/La-Liga-Stats"
        ]
        
        print(f"üèÜ Testando com {len(competition_urls)} competi√ß√µes...")
        
        async with FBRefPlaywrightScraper(headless=False) as scraper:
            print("‚úÖ Scraper iniciado com sucesso")
            
            # Coletar lista de competi√ß√µes
            print("\nüìä Coletando lista de competi√ß√µes...")
            competitions = await scraper.collect_competitions()
            print(f"‚úÖ {len(competitions)} competi√ß√µes encontradas")
            
            # Coletar detalhes de uma competi√ß√£o
            if competitions:
                print(f"\nüèÜ Coletando detalhes de: {competitions[0]['name']}")
                comp_details = await scraper.collect_competition_details(competitions[0]['url'])
                if comp_details:
                    print(f"‚úÖ Detalhes coletados: {comp_details.get('title', 'N/A')}")
                    print(f"üìä Estat√≠sticas: {len(comp_details.get('stats', []))} tabelas")
            
            # Coletar partidas
            print(f"\n‚öΩ Coletando partidas da Premier League...")
            matches = await scraper.collect_matches(competition_urls[0])
            print(f"‚úÖ {len(matches)} partidas coletadas")
            
            # Mostrar algumas partidas
            if matches:
                print("\nüìã Exemplos de partidas:")
                for i, match in enumerate(matches[:3]):
                    print(f"  {i+1}. {match.get('home_team', 'N/A')} vs {match.get('away_team', 'N/A')}")
                    print(f"     Data: {match.get('date', 'N/A')}")
                    print(f"     Placar: {match.get('score', 'N/A')}")
                    print()
            
            # Screenshot da p√°gina atual
            screenshot_path = await scraper.take_screenshot("fbref_demo.png")
            if screenshot_path:
                print(f"üì∏ Screenshot salvo: {screenshot_path}")
            
            # Dados interceptados
            intercepted_data = scraper.get_intercepted_data()
            print(f"üîç {len(intercepted_data['requests'])} requisi√ß√µes interceptadas")
            
        print("‚úÖ Demonstra√ß√£o do FBRef conclu√≠da com sucesso!")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro na demonstra√ß√£o do FBRef: {e}")
        import traceback
        traceback.print_exc()
        return False

async def demo_sofascore_scraper():
    """Demonstra o scraper do SofaScore com Playwright."""
    print("\n" + "="*60)
    print("üé≠ DEMONSTRA√á√ÉO DO SCRAPER SOFASCORE COM PLAYWRIGHT")
    print("="*60)
    
    try:
        from Coleta_de_dados.apis.sofascore.playwright_scraper import SofaScorePlaywrightScraper
        
        # URLs de teste
        urls = {
            "live": ["https://www.sofascore.com/football/live"],
            "teams": [
                "https://www.sofascore.com/team/manchester-united/17"
            ],
            "tournaments": [
                "https://www.sofascore.com/tournament/england-premier-league/7"
            ]
        }
        
        print(f"‚öΩ Testando com {sum(len(url_list) for url_list in urls.values())} URLs...")
        
        async with SofaScorePlaywrightScraper(headless=False) as scraper:
            print("‚úÖ Scraper iniciado com sucesso")
            
            # Coletar partidas ao vivo
            print("\nüìä Coletando partidas ao vivo...")
            live_matches = await scraper.collect_live_matches()
            print(f"‚úÖ {len(live_matches)} partidas ao vivo encontradas")
            
            # Mostrar algumas partidas ao vivo
            if live_matches:
                print("\nüìã Exemplos de partidas ao vivo:")
                for i, match in enumerate(live_matches[:3]):
                    print(f"  {i+1}. {match.get('title', 'N/A')}")
                    print(f"     URL: {match.get('url', 'N/A')}")
                    print()
            
            # Coletar partidas de um time
            print(f"\n‚öΩ Coletando partidas do Manchester United...")
            team_matches = await scraper.collect_team_matches(urls["teams"][0], limit=5)
            print(f"‚úÖ {len(team_matches)} partidas do time coletadas")
            
            # Screenshot da p√°gina atual
            screenshot_path = await scraper.take_screenshot("sofascore_demo.png")
            if screenshot_path:
                print(f"üì∏ Screenshot salvo: {screenshot_path}")
            
            # Dados interceptados
            intercepted_data = scraper.get_intercepted_data()
            print(f"üîç {len(intercepted_data['requests'])} requisi√ß√µes interceptadas")
            
        print("‚úÖ Demonstra√ß√£o do SofaScore conclu√≠da com sucesso!")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro na demonstra√ß√£o do SofaScore: {e}")
        import traceback
        traceback.print_exc()
        return False

async def demo_playwright_features():
    """Demonstra funcionalidades avan√ßadas do Playwright."""
    print("\n" + "="*60)
    print("üé≠ DEMONSTRA√á√ÉO DAS FUNCIONALIDADES AVAN√áADAS DO PLAYWRIGHT")
    print("="*60)
    
    try:
        from Coleta_de_dados.apis.playwright_base import PlaywrightBaseScraper
        
        print("üöÄ Testando funcionalidades avan√ßadas...")
        
        async with PlaywrightBaseScraper(
            headless=False,
            enable_video=True,
            enable_har=True
        ) as scraper:
            print("‚úÖ Scraper base iniciado com sucesso")
            
            # Navegar para uma p√°gina de teste
            test_url = "https://httpbin.org/headers"
            print(f"\nüåê Navegando para: {test_url}")
            
            if await scraper.navigate_to(test_url):
                print("‚úÖ Navega√ß√£o bem-sucedida")
                
                # Aguardar elemento espec√≠fico
                if await scraper.wait_for_element("pre"):
                    print("‚úÖ Elemento 'pre' encontrado")
                    
                    # Obter conte√∫do da p√°gina
                    content = await scraper.get_page_content()
                    if "User-Agent" in content:
                        print("‚úÖ Conte√∫do da p√°gina obtido com sucesso")
                    
                    # Executar JavaScript
                    js_result = await scraper.evaluate_javascript("document.title")
                    print(f"‚ö° JavaScript executado: {js_result}")
                    
                    # Screenshot
                    screenshot_path = await scraper.take_screenshot("playwright_features_demo.png")
                    if screenshot_path:
                        print(f"üì∏ Screenshot salvo: {screenshot_path}")
                    
                    # Dados interceptados
                    intercepted_data = scraper.get_intercepted_data()
                    print(f"üîç {len(intercepted_data['requests'])} requisi√ß√µes interceptadas")
                    
                    # Mostrar algumas requisi√ß√µes
                    if intercepted_data['requests']:
                        print("\nüìã Exemplos de requisi√ß√µes interceptadas:")
                        for i, req in enumerate(intercepted_data['requests'][:3]):
                            print(f"  {i+1}. {req['method']} {req['url']}")
                            print(f"     Timestamp: {req['timestamp']}")
                            print()
                else:
                    print("‚ö†Ô∏è Elemento 'pre' n√£o encontrado")
            else:
                print("‚ùå Falha na navega√ß√£o")
        
        print("‚úÖ Demonstra√ß√£o das funcionalidades conclu√≠da com sucesso!")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro na demonstra√ß√£o das funcionalidades: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """Fun√ß√£o principal de demonstra√ß√£o."""
    print("üöÄ DEMONSTRA√á√ÉO COMPLETA DOS SCRAPERS COM PLAYWRIGHT")
    print("="*60)
    print("üé≠ Playwright da Microsoft - Web Scraping Avan√ßado")
    print("üìä Funcionalidades: Anti-detec√ß√£o, Screenshots, Intercepta√ß√£o")
    print("üåê Navegadores: Chromium, Firefox, WebKit")
    print("="*60)
    
    start_time = time.time()
    results = []
    
    try:
        # Demonstra√ß√£o 1: Funcionalidades base do Playwright
        print("\n1Ô∏è‚É£ TESTANDO FUNCIONALIDADES BASE DO PLAYWRIGHT...")
        result1 = await demo_playwright_features()
        results.append(("Funcionalidades Base", result1))
        
        # Demonstra√ß√£o 2: Scraper do FBRef
        print("\n2Ô∏è‚É£ TESTANDO SCRAPER DO FBREF...")
        result2 = await demo_fbref_scraper()
        results.append(("FBRef Scraper", result2))
        
        # Demonstra√ß√£o 3: Scraper do SofaScore
        print("\n3Ô∏è‚É£ TESTANDO SCRAPER DO SOFASCORE...")
        result3 = await demo_sofascore_scraper()
        results.append(("SofaScore Scraper", result3))
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Demonstra√ß√£o interrompida pelo usu√°rio")
    except Exception as e:
        print(f"\n‚ùå Erro geral na demonstra√ß√£o: {e}")
        import traceback
        traceback.print_exc()
    
    # Resultados finais
    end_time = time.time()
    duration = end_time - start_time
    
    print("\n" + "="*60)
    print("üìä RESULTADOS DA DEMONSTRA√á√ÉO")
    print("="*60)
    
    for name, result in results:
        status = "‚úÖ SUCESSO" if result else "‚ùå FALHA"
        print(f"{name}: {status}")
    
    success_count = sum(1 for _, result in results if result)
    total_count = len(results)
    
    print(f"\nüéØ Resumo: {success_count}/{total_count} testes passaram")
    print(f"‚è±Ô∏è Dura√ß√£o total: {duration:.2f} segundos")
    
    if success_count == total_count:
        print("\nüéâ TODAS AS DEMONSTRA√á√ïES PASSARAM!")
        print("‚úÖ Playwright est√° funcionando perfeitamente")
        print("‚úÖ Scrapers est√£o operacionais")
        print("‚úÖ Sistema pronto para produ√ß√£o")
    else:
        print(f"\n‚ö†Ô∏è {total_count - success_count} demonstra√ß√£o(√µes) falharam")
        print("üîß Verifique os logs para identificar problemas")
    
    print("\nüöÄ PR√ìXIMOS PASSOS:")
    print("1. Configurar scrapers para produ√ß√£o")
    print("2. Implementar agendamento autom√°tico")
    print("3. Configurar monitoramento e alertas")
    print("4. Integrar com sistema de ML")
    print("5. Implementar cache e otimiza√ß√µes")

if __name__ == "__main__":
    # Executar demonstra√ß√£o
    asyncio.run(main())
